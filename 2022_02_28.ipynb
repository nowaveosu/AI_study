{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "straight-pierre",
   "metadata": {},
   "source": [
    "### Linear Regression(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "visible-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차, 손실함수(loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latest-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#회귀는 트레이닝 데이터를 이용하여 데이터의 특성, 상관관계등을  파악하고 결과를 바탕으로 \n",
    "#미지의 데이터가 주어졌을때 결과를 연속적인 숫자값으로 예측하는것\n",
    "#공부시간, 시험성적을 인풋, 러닝후 새로운 공부시간을 넣었을 때 시험성적을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quiet-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#머신러닝은 트레이닝 데이터를 분석하고 데이터를 가장 잘 나타내는 y = Wx+b를 찾아내는것\n",
    "# W(기울기), b(y)절편을 찾는것이 학습(learning)개념임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-northwest",
   "metadata": {},
   "source": [
    "#### 회귀(regression) - 오차(error), 가중치(weight)W, 바이어스(bias)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "artistic-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레이닝 데이터의 정답 t와 직선 y = wx+b차이인 오차는\n",
    "# error = t-y = t- (wx+b)로 계산된다\n",
    "# 오차가 크면 w, b값이 잘못된것이고 오차가 작다면 w, b값이 잘된것, 미래값 예측도 정확할것임\n",
    "# 즉 W, b값을 잘 찾아야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-plain",
   "metadata": {},
   "source": [
    "#### 회귀 - 손실함수(loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "disturbed-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 loss function 또는 cost function 은 training data의 정답 t와 입력 x에 대한 계산 값 y의 차이를 모두 더해 수식으로 나타낸것\n",
    "#즉 각각의 오차인 t-y를 모두 더하는건데, 오차가 + ,-가 존재해서 오차의 합이 0이 나와버릴수 있으니\n",
    "#손실함수에서는 오차를 계산할때 (t-y)^2 을 사용함. 계산값 차이가 크다면 결과도 크게 나타나게됨\n",
    "# 각각 값마다 (t-y)제곱한걸 모두 더한뒤 트레이닝 데이터 수 n으로 나누면 그게 손실함수값임\n",
    "# E(W,b) = 1/n 시그마[t-y]^2 \n",
    "# 여기서 x, t는 주어진값이므로 결국 손실함수 E(W,b)는 W,b에 영향을 받는 함수임\n",
    "# E(W,b)가 최소값을 갖게하는 W,b를 구하는것이 최종목적임"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
