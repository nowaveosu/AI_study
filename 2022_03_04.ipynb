{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f58145-f1d4-4b5f-80d3-bfd40eab1bb2",
   "metadata": {},
   "source": [
    "### logistic regression II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60c0605-a3f7-4d2b-8b61-20db38e207b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. x와 정답 t를 분리 (t는 0or1)\n",
    "# 2. z=Wx+b에서 W,b값 랜덤부여\n",
    "# 3. y=sigmoid(z) E(W,b) 손실함수 정의\n",
    "# 4. 학습율 a 적당히 1e-3\n",
    "# 5. W,b업데이트하며 손실함수 최소값찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195025dd-f3ed-4975-bde0-e4e97d91133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세로로 길쭉한 행렬 x와 W+b하면 z행렬나오고 시그모이드 취하면 Y행렬이 나옴, 그거랑 T행렬 비교하면끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8355b714-416e-4e7d-96ec-219acb764765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (10, 1) , t_data.shape =  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "#1학습데이터준비\n",
    "import numpy as np\n",
    "#10*1 길쭉한행렬로 reshape\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10,1)   \n",
    "t_data = np.array([0, 0, 0, 0,  0,  0,  1,  1,  1,  1]).reshape(10,1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3718983-cfe5-4ae8-a8b8-30a2699bfbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.66844148]] , W.shape =  (1, 1) , b =  [0.3764958] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "#2임의의 직선 z=Wx+b정의\n",
    "W = np.random.rand(1,1)  \n",
    "b = np.random.rand(1)  \n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24937665-a457-4e77-874c-3ecff5567454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종출력은 y = sigmoid(Wx+b) 이며, 손실함수는 cross-entropy 로 나타냄\n",
    "# 3손실함수 E(W,b)정의\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7    # log 무한대 발산 방지, 매우작은수 더해줌\n",
    "    \n",
    "    z = np.dot(x,W) + b #z값 계산후 y값 구하기\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81923af1-6396-4ecd-ad79-a855e51d5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4수치미분함수정의, 유틸리티함수정의\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f05bafa-bc1e-470e-b662-f73da44e8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) \n",
    "\n",
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy type\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y >= 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f94d0e1-bc82-466d-a956-dcceb89ee997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  0.620881966584359 Initial W =  [[1.15307549]] \n",
      " , b =  [-14.86547826]\n",
      "step =  0 error value =  0.6208528702758342 W =  [[1.15311669]] , b =  [-14.86601725]\n",
      "step =  400 error value =  0.6095057610995075 W =  [[1.16939226]] , b =  [-15.07888707]\n",
      "step =  800 error value =  0.5987064178825202 W =  [[1.18527274]] , b =  [-15.28654928]\n",
      "step =  1200 error value =  0.5884090678655152 W =  [[1.20078213]] , b =  [-15.48932193]\n",
      "step =  1600 error value =  0.5785732923742689 W =  [[1.21594213]] , b =  [-15.68749256]\n",
      "step =  2000 error value =  0.5691632372595934 W =  [[1.23077244]] , b =  [-15.88132206]\n",
      "step =  2400 error value =  0.5601469619903479 W =  [[1.24529099]] , b =  [-16.07104794]\n",
      "step =  2800 error value =  0.5514958994171502 W =  [[1.25951419]] , b =  [-16.25688714]\n",
      "step =  3200 error value =  0.5431844045586844 W =  [[1.27345706]] , b =  [-16.43903839]\n",
      "step =  3600 error value =  0.5351893755157406 W =  [[1.28713339]] , b =  [-16.61768423]\n",
      "step =  4000 error value =  0.5274899332216704 W =  [[1.3005559]] , b =  [-16.79299282]\n",
      "step =  4400 error value =  0.520067149492273 W =  [[1.31373634]] , b =  [-16.96511938]\n",
      "step =  4800 error value =  0.5129038149623752 W =  [[1.3266856]] , b =  [-17.1342076]\n",
      "step =  5200 error value =  0.5059842401474097 W =  [[1.33941374]] , b =  [-17.30039072]\n",
      "step =  5600 error value =  0.499294084159923 W =  [[1.35193015]] , b =  [-17.46379262]\n",
      "step =  6000 error value =  0.4928202066308994 W =  [[1.36424358]] , b =  [-17.62452864]\n",
      "step =  6400 error value =  0.4865505391935562 W =  [[1.37636217]] , b =  [-17.78270641]\n",
      "step =  6800 error value =  0.4804739735333807 W =  [[1.38829355]] , b =  [-17.93842653]\n",
      "step =  7200 error value =  0.47458026352726296 W =  [[1.40004486]] , b =  [-18.09178319]\n",
      "step =  7600 error value =  0.4688599394130068 W =  [[1.4116228]] , b =  [-18.24286473]\n",
      "step =  8000 error value =  0.46330423227141254 W =  [[1.42303366]] , b =  [-18.39175413]\n",
      "step =  8400 error value =  0.45790500738068773 W =  [[1.43428336]] , b =  [-18.53852944]\n",
      "step =  8800 error value =  0.45265470523079926 W =  [[1.44537748]] , b =  [-18.68326419]\n",
      "step =  9200 error value =  0.44754628917344896 W =  [[1.45632128]] , b =  [-18.82602773]\n",
      "step =  9600 error value =  0.4425731988383109 W =  [[1.46711974]] , b =  [-18.96688557]\n",
      "step =  10000 error value =  0.4377293085757723 W =  [[1.47777756]] , b =  [-19.10589965]\n"
     ]
    }
   ],
   "source": [
    "#5 학습율 초기화 및 W,b업데이트\n",
    "learning_rate = 1e-2  # 적당히해놓고 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)  # f(x) = loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "for step in  range(10001):  \n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6deebdcc-ce80-4e2d-b1eb-48e743c01681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.2440935e-07]] 0\n"
     ]
    }
   ],
   "source": [
    "#손실함수는 0.4까지 작아지고 W는 1, b는 -19정도에서 수렴\n",
    "(real_val, logical_val) = predict(3)\n",
    "print(real_val, logical_val)\n",
    "#3시간 공부해서 합격할확률 0.4, 0(불합격)일것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018778e3-76bc-4107-8893-e44d5364c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9975673]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(17)\n",
    "print(real_val, logical_val)\n",
    "#17시간 공부해서 합격할확률 99퍼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b8988-5314-4045-9837-bb97993c5d54",
   "metadata": {},
   "source": [
    "#### 입력변수 여러개, 정답은 0,1인 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ddee486-f871-492c-97a0-29380f08efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력변수 여러개, 정답은 0,1인 logistic regression\n",
    "# 입력행렬 X(9x2)*W(2*1) = Z(9x1) , 시그취하면 Y(9x1) 정답행렬 T(9x1), Y,T비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a4e74c-aaeb-4027-90aa-095a2ff9c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (9, 2)\n",
      "t_data.ndim =  2 , t_data.shape =  (9, 1)\n"
     ]
    }
   ],
   "source": [
    "#1.학습데이터 준비\n",
    "import numpy as np\n",
    "#x는 9x2행렬, t행렬은 9x1, 행렬을 위해 reshape해주었다\n",
    "x_data = np.array([ [2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7] ])\n",
    "t_data = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1]).reshape(9, 1)\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15ae4163-5d51-4791-a2a3-bdac54c926e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.02817985]\n",
      " [0.89078425]] , W.shape =  (2, 1) , b =  [0.54486994] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "#2. z=W1x1+W2x2+b정의\n",
    "#W를 x에 맞춰서 2x1로 맞춰줌, 임의값넣음\n",
    "W = np.random.rand(2, 1)  # 2X1 행렬\n",
    "b = np.random.rand(1)  \n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0375a0f1-1501-4d2a-8276-dc7de2f07251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification 이므로 출력함수로 sigmoid 정의\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9726b35b-beb6-4ed0-a507-d389c4ccafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.손실함수 정의\n",
    "# 최종출력은 y = sigmoid(Wx+b) 이며, 손실함수는 cross-entropy 로 나타냄\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f873910a-e912-47d6-b209-8846d64f0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 수치미분 및 유틸리티함수 정의\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f167e723-fb59-401e-a37d-ccdf59d1763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 학습율 초기화 및 손실함수가 최소될때까지 W,b업뎃\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) )  \n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab6c422-e435-43f3-89d4-e4d85d65c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  25.950141576523826 Initial W =  [[0.02817985]\n",
      " [0.89078425]] \n",
      " , b =  [0.54486994]\n",
      "step =  0 error value =  16.412986396264664 W =  [[-0.16656686]\n",
      " [ 0.63307161]] , b =  [0.51415834]\n",
      "step =  400 error value =  2.2664009365871496 W =  [[ 0.4211749 ]\n",
      " [-0.08637499]] , b =  [-2.63599727]\n",
      "step =  800 error value =  1.5885641136812076 W =  [[ 0.53686413]\n",
      " [-0.02613457]] , b =  [-4.2703486]\n",
      "step =  1200 error value =  1.2785116073980873 W =  [[0.62386297]\n",
      " [0.00918234]] , b =  [-5.38009938]\n",
      "step =  1600 error value =  1.097242795813834 W =  [[0.69411041]\n",
      " [0.03435652]] , b =  [-6.22953811]\n",
      "step =  2000 error value =  0.9759997745386543 W =  [[0.75333078]\n",
      " [0.054411  ]] , b =  [-6.92445451]\n",
      "step =  2400 error value =  0.8877478240908283 W =  [[0.80468378]\n",
      " [0.07157614]] , b =  [-7.51737455]\n",
      "step =  2800 error value =  0.8196971685460933 W =  [[0.85010014]\n",
      " [0.08700573]] , b =  [-8.03802385]\n",
      "step =  3200 error value =  0.7650002715552927 W =  [[0.89085009]\n",
      " [0.10135705]] , b =  [-8.50478543]\n",
      "step =  3600 error value =  0.7196491536895773 W =  [[0.92781765]\n",
      " [0.11502871]] , b =  [-8.92978692]\n",
      "step =  4000 error value =  0.6811341348519336 W =  [[0.96164624]\n",
      " [0.12827181]] , b =  [-9.32143408]\n",
      "step =  4400 error value =  0.6477984448740522 W =  [[0.99282183]\n",
      " [0.14124704]] , b =  [-9.68578459]\n",
      "step =  4800 error value =  0.6185009158085215 W =  [[1.02172324]\n",
      " [0.15405641]] , b =  [-10.02734363]\n",
      "step =  5200 error value =  0.5924276714043749 W =  [[1.04865388]\n",
      " [0.16676213]] , b =  [-10.34954974]\n",
      "step =  5600 error value =  0.568981164455357 W =  [[1.07386239]\n",
      " [0.17939859]] , b =  [-10.65508484]\n",
      "step =  6000 error value =  0.5477117734801403 W =  [[1.09755648]\n",
      " [0.19198059]] , b =  [-10.94607936]\n",
      "step =  6400 error value =  0.5282739879763535 W =  [[1.11991232]\n",
      " [0.20450917]] , b =  [-11.22425253]\n",
      "step =  6800 error value =  0.5103974034319022 W =  [[1.14108103]\n",
      " [0.21697604]] , b =  [-11.49101086]\n",
      "step =  7200 error value =  0.4938669636861955 W =  [[1.16119331]\n",
      " [0.22936708]] , b =  [-11.74751904]\n",
      "step =  7600 error value =  0.4785091629774121 W =  [[1.18036277]\n",
      " [0.24166495]] , b =  [-11.99475203]\n",
      "step =  8000 error value =  0.4641821980381139 W =  [[1.19868844]\n",
      " [0.25385111]] , b =  [-12.23353412]\n",
      "step =  8400 error value =  0.45076880446851997 W =  [[1.2162567 ]\n",
      " [0.26590737]] , b =  [-12.46456859]\n",
      "step =  8800 error value =  0.43817095828280195 W =  [[1.23314298]\n",
      " [0.27781687]] , b =  [-12.68846063]\n",
      "step =  9200 error value =  0.4263058993402517 W =  [[1.24941302]\n",
      " [0.28956476]] , b =  [-12.90573521]\n",
      "step =  9600 error value =  0.41510310810154877 W =  [[1.26512418]\n",
      " [0.30113852]] , b =  [-13.11685119]\n",
      "step =  10000 error value =  0.40450198051217484 W =  [[1.28032641]\n",
      " [0.31252809]] , b =  [-13.3222125]\n",
      "step =  10400 error value =  0.3944500210232232 W =  [[1.29506328]\n",
      " [0.32372585]] , b =  [-13.52217717]\n",
      "step =  10800 error value =  0.38490142471366445 W =  [[1.3093728 ]\n",
      " [0.33472636]] , b =  [-13.71706452]\n",
      "step =  11200 error value =  0.3758159546721847 W =  [[1.32328817]\n",
      " [0.34552626]] , b =  [-13.90716106]\n",
      "step =  11600 error value =  0.3671580455370829 W =  [[1.33683848]\n",
      " [0.35612389]] , b =  [-14.09272531]\n",
      "step =  12000 error value =  0.3588960817534151 W =  [[1.35004926]\n",
      " [0.36651913]] , b =  [-14.27399174]\n",
      "step =  12400 error value =  0.35100181188993484 W =  [[1.362943  ]\n",
      " [0.37671307]] , b =  [-14.45117399]\n",
      "step =  12800 error value =  0.34344986971688257 W =  [[1.37553961]\n",
      " [0.38670783]] , b =  [-14.62446762]\n",
      "step =  13200 error value =  0.3362173796672515 W =  [[1.38785673]\n",
      " [0.39650634]] , b =  [-14.79405236]\n",
      "step =  13600 error value =  0.32928362946905676 W =  [[1.39991015]\n",
      " [0.40611213]] , b =  [-14.96009398]\n",
      "step =  14000 error value =  0.3226297966192524 W =  [[1.41171396]\n",
      " [0.41552923]] , b =  [-15.12274593]\n",
      "step =  14400 error value =  0.3162387183092845 W =  [[1.42328088]\n",
      " [0.42476199]] , b =  [-15.28215068]\n",
      "step =  14800 error value =  0.3100946966532601 W =  [[1.43462241]\n",
      " [0.43381502]] , b =  [-15.4384409]\n",
      "step =  15200 error value =  0.3041833327857833 W =  [[1.44574899]\n",
      " [0.44269306]] , b =  [-15.59174044]\n",
      "step =  15600 error value =  0.2984913847222807 W =  [[1.45667014]\n",
      " [0.45140094]] , b =  [-15.74216522]\n",
      "step =  16000 error value =  0.2930066448996021 W =  [[1.4673946 ]\n",
      " [0.45994351]] , b =  [-15.88982394]\n",
      "step =  16400 error value =  0.28771783411668517 W =  [[1.47793041]\n",
      " [0.46832561]] , b =  [-16.03481879]\n",
      "step =  16800 error value =  0.2826145092223673 W =  [[1.48828499]\n",
      " [0.476552  ]] , b =  [-16.17724597]\n",
      "step =  17200 error value =  0.277686982392231 W =  [[1.49846522]\n",
      " [0.4846274 ]] , b =  [-16.31719623]\n",
      "step =  17600 error value =  0.2729262502291446 W =  [[1.50847751]\n",
      " [0.49255638]] , b =  [-16.45475532]\n",
      "step =  18000 error value =  0.26832393123494247 W =  [[1.51832784]\n",
      " [0.50034343]] , b =  [-16.59000435]\n",
      "step =  18400 error value =  0.26387221045117804 W =  [[1.52802181]\n",
      " [0.50799291]] , b =  [-16.72302018]\n",
      "step =  18800 error value =  0.2595637902692299 W =  [[1.53756465]\n",
      " [0.51550903]] , b =  [-16.85387574]\n",
      "step =  19200 error value =  0.25539184657344866 W =  [[1.54696132]\n",
      " [0.52289589]] , b =  [-16.9826403]\n",
      "step =  19600 error value =  0.2513499895146235 W =  [[1.55621647]\n",
      " [0.53015742]] , b =  [-17.10937972]\n",
      "step =  20000 error value =  0.24743222832005068 W =  [[1.56533452]\n",
      " [0.53729744]] , b =  [-17.23415671]\n",
      "step =  20400 error value =  0.24363293963630633 W =  [[1.57431962]\n",
      " [0.54431961]] , b =  [-17.35703102]\n",
      "step =  20800 error value =  0.23994683897504474 W =  [[1.58317575]\n",
      " [0.55122749]] , b =  [-17.47805965]\n",
      "step =  21200 error value =  0.23636895489412166 W =  [[1.59190666]\n",
      " [0.55802447]] , b =  [-17.59729702]\n",
      "step =  21600 error value =  0.23289460559750047 W =  [[1.60051593]\n",
      " [0.56471383]] , b =  [-17.71479512]\n",
      "step =  22000 error value =  0.2295193776808975 W =  [[1.60900698]\n",
      " [0.57129872]] , b =  [-17.83060367]\n",
      "step =  22400 error value =  0.22623910678655398 W =  [[1.61738306]\n",
      " [0.57778218]] , b =  [-17.94477026]\n",
      "step =  22800 error value =  0.22304985996106383 W =  [[1.62564729]\n",
      " [0.58416713]] , b =  [-18.05734047]\n",
      "step =  23200 error value =  0.2199479195366863 W =  [[1.63380265]\n",
      " [0.59045636]] , b =  [-18.16835797]\n",
      "step =  23600 error value =  0.21692976837881814 W =  [[1.64185198]\n",
      " [0.59665258]] , b =  [-18.27786466]\n",
      "step =  24000 error value =  0.21399207636120365 W =  [[1.64979803]\n",
      " [0.60275838]] , b =  [-18.38590074]\n",
      "step =  24400 error value =  0.2111316879472973 W =  [[1.65764341]\n",
      " [0.60877626]] , b =  [-18.49250483]\n",
      "step =  24800 error value =  0.2083456107700805 W =  [[1.66539065]\n",
      " [0.61470861]] , b =  [-18.59771401]\n",
      "step =  25200 error value =  0.20563100511489035 W =  [[1.67304217]\n",
      " [0.62055775]] , b =  [-18.70156396]\n",
      "step =  25600 error value =  0.2029851742207819 W =  [[1.6806003 ]\n",
      " [0.62632591]] , b =  [-18.80408899]\n",
      "step =  26000 error value =  0.20040555532484966 W =  [[1.68806728]\n",
      " [0.63201521]] , b =  [-18.90532211]\n",
      "step =  26400 error value =  0.19788971138231237 W =  [[1.69544527]\n",
      " [0.63762772]] , b =  [-19.00529513]\n",
      "step =  26800 error value =  0.19543532340215633 W =  [[1.70273636]\n",
      " [0.64316543]] , b =  [-19.10403867]\n",
      "step =  27200 error value =  0.19304018334431022 W =  [[1.70994255]\n",
      " [0.64863024]] , b =  [-19.20158229]\n",
      "step =  27600 error value =  0.19070218753006515 W =  [[1.71706578]\n",
      " [0.65402401]] , b =  [-19.29795444]\n",
      "step =  28000 error value =  0.18841933052199986 W =  [[1.72410791]\n",
      " [0.6593485 ]] , b =  [-19.39318262]\n",
      "step =  28400 error value =  0.1861896994341579 W =  [[1.73107076]\n",
      " [0.66460544]] , b =  [-19.48729334]\n",
      "step =  28800 error value =  0.18401146863700507 W =  [[1.73795608]\n",
      " [0.66979646]] , b =  [-19.58031222]\n",
      "step =  29200 error value =  0.18188289482501616 W =  [[1.74476554]\n",
      " [0.67492318]] , b =  [-19.672264]\n",
      "step =  29600 error value =  0.17980231241786682 W =  [[1.75150079]\n",
      " [0.67998712]] , b =  [-19.76317258]\n",
      "step =  30000 error value =  0.17776812926869048 W =  [[1.7581634 ]\n",
      " [0.68498977]] , b =  [-19.8530611]\n",
      "step =  30400 error value =  0.17577882265570957 W =  [[1.7647549 ]\n",
      " [0.68993258]] , b =  [-19.94195191]\n",
      "step =  30800 error value =  0.17383293553507626 W =  [[1.77127678]\n",
      " [0.69481691]] , b =  [-20.02986665]\n",
      "step =  31200 error value =  0.17192907303515412 W =  [[1.77773047]\n",
      " [0.69964412]] , b =  [-20.11682626]\n",
      "step =  31600 error value =  0.17006589917421702 W =  [[1.78411736]\n",
      " [0.70441551]] , b =  [-20.20285103]\n",
      "step =  32000 error value =  0.16824213378482758 W =  [[1.79043881]\n",
      " [0.70913231]] , b =  [-20.28796058]\n",
      "step =  32400 error value =  0.16645654962972667 W =  [[1.79669611]\n",
      " [0.71379576]] , b =  [-20.37217396]\n",
      "step =  32800 error value =  0.16470796969546397 W =  [[1.80289055]\n",
      " [0.71840701]] , b =  [-20.4555096]\n",
      "step =  33200 error value =  0.16299526465085526 W =  [[1.80902335]\n",
      " [0.72296721]] , b =  [-20.53798541]\n",
      "step =  33600 error value =  0.16131735045876403 W =  [[1.81509572]\n",
      " [0.72747745]] , b =  [-20.61961871]\n",
      "step =  34000 error value =  0.15967318613028988 W =  [[1.8211088]\n",
      " [0.7319388]] , b =  [-20.70042635]\n",
      "step =  34400 error value =  0.15806177161164392 W =  [[1.82706374]\n",
      " [0.7363523 ]] , b =  [-20.78042466]\n",
      "step =  34800 error value =  0.15648214579440367 W =  [[1.83296163]\n",
      " [0.74071894]] , b =  [-20.85962949]\n",
      "step =  35200 error value =  0.15493338464104545 W =  [[1.83880353]\n",
      " [0.74503969]] , b =  [-20.93805623]\n",
      "step =  35600 error value =  0.15341459941772367 W =  [[1.84459049]\n",
      " [0.74931549]] , b =  [-21.01571985]\n",
      "step =  36000 error value =  0.151924935027393 W =  [[1.85032351]\n",
      " [0.75354725]] , b =  [-21.09263488]\n",
      "step =  36400 error value =  0.15046356843651257 W =  [[1.85600357]\n",
      " [0.75773587]] , b =  [-21.16881543]\n",
      "step =  36800 error value =  0.14902970718931427 W =  [[1.86163163]\n",
      " [0.76188219]] , b =  [-21.24427524]\n",
      "step =  37200 error value =  0.14762258800399583 W =  [[1.86720862]\n",
      " [0.76598706]] , b =  [-21.31902766]\n",
      "step =  37600 error value =  0.14624147544550262 W =  [[1.87273545]\n",
      " [0.77005127]] , b =  [-21.39308566]\n",
      "step =  38000 error value =  0.1448856606701637 W =  [[1.87821299]\n",
      " [0.77407562]] , b =  [-21.46646188]\n",
      "step =  38400 error value =  0.14355446023759785 W =  [[1.8836421 ]\n",
      " [0.77806088]] , b =  [-21.53916862]\n",
      "step =  38800 error value =  0.14224721498577494 W =  [[1.88902362]\n",
      " [0.78200778]] , b =  [-21.61121784]\n",
      "step =  39200 error value =  0.14096328896525617 W =  [[1.89435836]\n",
      " [0.78591705]] , b =  [-21.68262118]\n",
      "step =  39600 error value =  0.13970206842910715 W =  [[1.89964713]\n",
      " [0.78978938]] , b =  [-21.75338999]\n",
      "step =  40000 error value =  0.13846296087505397 W =  [[1.90489069]\n",
      " [0.79362547]] , b =  [-21.82353533]\n",
      "step =  40400 error value =  0.1372453941367104 W =  [[1.91008979]\n",
      " [0.79742597]] , b =  [-21.89306795]\n",
      "step =  40800 error value =  0.13604881552108383 W =  [[1.91524518]\n",
      " [0.80119153]] , b =  [-21.96199835]\n",
      "step =  41200 error value =  0.13487269098953814 W =  [[1.92035758]\n",
      " [0.80492278]] , b =  [-22.03033676]\n",
      "step =  41600 error value =  0.1337165043797053 W =  [[1.92542768]\n",
      " [0.80862034]] , b =  [-22.09809313]\n",
      "step =  42000 error value =  0.13257975666595892 W =  [[1.93045617]\n",
      " [0.81228479]] , b =  [-22.1652772]\n",
      "step =  42400 error value =  0.13146196525625564 W =  [[1.93544372]\n",
      " [0.81591673]] , b =  [-22.23189844]\n",
      "step =  42800 error value =  0.13036266332331378 W =  [[1.94039098]\n",
      " [0.81951671]] , b =  [-22.2979661]\n",
      "step =  43200 error value =  0.1292813991680511 W =  [[1.94529858]\n",
      " [0.82308528]] , b =  [-22.3634892]\n",
      "step =  43600 error value =  0.12821773561368793 W =  [[1.95016716]\n",
      " [0.82662299]] , b =  [-22.42847656]\n",
      "step =  44000 error value =  0.12717124942860297 W =  [[1.95499731]\n",
      " [0.83013035]] , b =  [-22.49293676]\n",
      "step =  44400 error value =  0.12614153077647178 W =  [[1.95978963]\n",
      " [0.83360789]] , b =  [-22.5568782]\n",
      "step =  44800 error value =  0.12512818269219575 W =  [[1.9645447 ]\n",
      " [0.83705608]] , b =  [-22.62030907]\n",
      "step =  45200 error value =  0.12413082058223328 W =  [[1.96926308]\n",
      " [0.84047543]] , b =  [-22.68323738]\n",
      "step =  45600 error value =  0.12314907174786387 W =  [[1.97394534]\n",
      " [0.8438664 ]] , b =  [-22.74567095]\n",
      "step =  46000 error value =  0.12218257493040768 W =  [[1.97859201]\n",
      " [0.84722946]] , b =  [-22.8076174]\n",
      "step =  46400 error value =  0.1212309798770767 W =  [[1.98320363]\n",
      " [0.85056505]] , b =  [-22.86908421]\n",
      "step =  46800 error value =  0.12029394692639489 W =  [[1.9877807 ]\n",
      " [0.85387362]] , b =  [-22.93007866]\n",
      "step =  47200 error value =  0.11937114661217174 W =  [[1.99232375]\n",
      " [0.8571556 ]] , b =  [-22.9906079]\n",
      "step =  47600 error value =  0.11846225928513669 W =  [[1.99683325]\n",
      " [0.86041141]] , b =  [-23.05067888]\n",
      "step =  48000 error value =  0.11756697475116856 W =  [[2.00130971]\n",
      " [0.86364145]] , b =  [-23.11029843]\n",
      "step =  48400 error value =  0.11668499192546712 W =  [[2.00575359]\n",
      " [0.86684613]] , b =  [-23.16947321]\n",
      "step =  48800 error value =  0.11581601850171785 W =  [[2.01016536]\n",
      " [0.87002584]] , b =  [-23.22820975]\n",
      "step =  49200 error value =  0.1149597706355204 W =  [[2.01454548]\n",
      " [0.87318096]] , b =  [-23.28651441]\n",
      "step =  49600 error value =  0.11411597264142964 W =  [[2.01889438]\n",
      " [0.87631186]] , b =  [-23.34439345]\n",
      "step =  50000 error value =  0.1132843567028678 W =  [[2.02321251]\n",
      " [0.87941891]] , b =  [-23.40185297]\n",
      "step =  50400 error value =  0.11246466259431084 W =  [[2.0275003 ]\n",
      " [0.88250247]] , b =  [-23.45889895]\n",
      "step =  50800 error value =  0.11165663741510197 W =  [[2.03175815]\n",
      " [0.88556289]] , b =  [-23.51553725]\n",
      "step =  51200 error value =  0.1108600353344167 W =  [[2.03598649]\n",
      " [0.88860051]] , b =  [-23.57177358]\n",
      "step =  51600 error value =  0.11007461734677257 W =  [[2.04018571]\n",
      " [0.89161565]] , b =  [-23.62761357]\n",
      "step =  52000 error value =  0.1093001510375147 W =  [[2.04435621]\n",
      " [0.89460866]] , b =  [-23.68306271]\n",
      "step =  52400 error value =  0.10853641035800429 W =  [[2.04849837]\n",
      " [0.89757984]] , b =  [-23.73812637]\n",
      "step =  52800 error value =  0.107783175409832 W =  [[2.05261258]\n",
      " [0.90052952]] , b =  [-23.79280984]\n",
      "step =  53200 error value =  0.10704023223779868 W =  [[2.05669919]\n",
      " [0.90345799]] , b =  [-23.84711827]\n",
      "step =  53600 error value =  0.10630737263111038 W =  [[2.06075858]\n",
      " [0.90636556]] , b =  [-23.90105674]\n",
      "step =  54000 error value =  0.105584393932524 W =  [[2.0647911 ]\n",
      " [0.90925253]] , b =  [-23.95463019]\n",
      "step =  54400 error value =  0.10487109885503738 W =  [[2.0687971 ]\n",
      " [0.91211917]] , b =  [-24.00784349]\n",
      "step =  54800 error value =  0.10416729530577568 W =  [[2.07277693]\n",
      " [0.91496577]] , b =  [-24.06070141]\n",
      "step =  55200 error value =  0.1034727962167031 W =  [[2.07673091]\n",
      " [0.9177926 ]] , b =  [-24.11320862]\n",
      "step =  55600 error value =  0.10278741938196143 W =  [[2.08065938]\n",
      " [0.92059995]] , b =  [-24.1653697]\n",
      "step =  56000 error value =  0.10211098730143389 W =  [[2.08456267]\n",
      " [0.92338806]] , b =  [-24.21718914]\n",
      "step =  56400 error value =  0.10144332703029676 W =  [[2.08844109]\n",
      " [0.9261572 ]] , b =  [-24.26867136]\n",
      "step =  56800 error value =  0.10078427003428171 W =  [[2.09229494]\n",
      " [0.92890763]] , b =  [-24.31982066]\n",
      "step =  57200 error value =  0.10013365205046541 W =  [[2.09612455]\n",
      " [0.93163959]] , b =  [-24.3706413]\n",
      "step =  57600 error value =  0.09949131295319844 W =  [[2.0999302 ]\n",
      " [0.93435333]] , b =  [-24.42113743]\n",
      "step =  58000 error value =  0.09885709662513097 W =  [[2.1037122 ]\n",
      " [0.93704909]] , b =  [-24.47131313]\n",
      "step =  58400 error value =  0.09823085083293685 W =  [[2.10747083]\n",
      " [0.9397271 ]] , b =  [-24.52117242]\n",
      "step =  58800 error value =  0.09761242710769763 W =  [[2.11120637]\n",
      " [0.94238759]] , b =  [-24.57071921]\n",
      "step =  59200 error value =  0.09700168062960667 W =  [[2.11491911]\n",
      " [0.94503078]] , b =  [-24.61995738]\n",
      "step =  59600 error value =  0.09639847011693418 W =  [[2.11860932]\n",
      " [0.94765691]] , b =  [-24.66889071]\n",
      "step =  60000 error value =  0.09580265771893395 W =  [[2.12227727]\n",
      " [0.95026618]] , b =  [-24.71752292]\n",
      "step =  60400 error value =  0.09521410891270975 W =  [[2.12592321]\n",
      " [0.95285882]] , b =  [-24.76585766]\n",
      "step =  60800 error value =  0.09463269240366962 W =  [[2.12954742]\n",
      " [0.95543502]] , b =  [-24.81389852]\n",
      "step =  61200 error value =  0.09405828002958323 W =  [[2.13315015]\n",
      " [0.95799499]] , b =  [-24.86164902]\n",
      "step =  61600 error value =  0.09349074666802872 W =  [[2.13673165]\n",
      " [0.96053894]] , b =  [-24.90911263]\n",
      "step =  62000 error value =  0.09292997014706393 W =  [[2.14029215]\n",
      " [0.96306707]] , b =  [-24.95629273]\n",
      "step =  62400 error value =  0.09237583115905446 W =  [[2.14383192]\n",
      " [0.96557956]] , b =  [-25.00319268]\n",
      "step =  62800 error value =  0.09182821317748302 W =  [[2.14735118]\n",
      " [0.96807661]] , b =  [-25.04981574]\n",
      "step =  63200 error value =  0.09128700237662431 W =  [[2.15085017]\n",
      " [0.9705584 ]] , b =  [-25.09616515]\n",
      "step =  63600 error value =  0.09075208755400357 W =  [[2.15432912]\n",
      " [0.97302512]] , b =  [-25.14224407]\n",
      "step =  64000 error value =  0.09022336005547439 W =  [[2.15778825]\n",
      " [0.97547696]] , b =  [-25.18805562]\n",
      "step =  64400 error value =  0.08970071370289624 W =  [[2.16122779]\n",
      " [0.97791408]] , b =  [-25.23360286]\n",
      "step =  64800 error value =  0.08918404472418032 W =  [[2.16464795]\n",
      " [0.98033666]] , b =  [-25.27888879]\n",
      "step =  65200 error value =  0.08867325168575008 W =  [[2.16804895]\n",
      " [0.98274487]] , b =  [-25.32391638]\n",
      "step =  65600 error value =  0.08816823542723776 W =  [[2.17143101]\n",
      " [0.98513888]] , b =  [-25.36868853]\n",
      "step =  66000 error value =  0.08766889899835856 W =  [[2.17479433]\n",
      " [0.98751886]] , b =  [-25.4132081]\n",
      "step =  66400 error value =  0.08717514759783845 W =  [[2.17813911]\n",
      " [0.98988496]] , b =  [-25.4574779]\n",
      "step =  66800 error value =  0.08668688851440827 W =  [[2.18146556]\n",
      " [0.99223735]] , b =  [-25.50150071]\n",
      "step =  67200 error value =  0.08620403106967384 W =  [[2.18477387]\n",
      " [0.99457619]] , b =  [-25.54527923]\n",
      "step =  67600 error value =  0.08572648656287975 W =  [[2.18806425]\n",
      " [0.99690162]] , b =  [-25.58881615]\n",
      "step =  68000 error value =  0.08525416821744591 W =  [[2.19133687]\n",
      " [0.99921381]] , b =  [-25.63211409]\n",
      "step =  68400 error value =  0.08478699112922006 W =  [[2.19459194]\n",
      " [1.00151289]] , b =  [-25.67517565]\n",
      "step =  68800 error value =  0.0843248722164101 W =  [[2.19782963]\n",
      " [1.00379902]] , b =  [-25.71800338]\n",
      "step =  69200 error value =  0.08386773017107271 W =  [[2.20105013]\n",
      " [1.00607234]] , b =  [-25.76059978]\n",
      "step =  69600 error value =  0.08341548541219759 W =  [[2.20425361]\n",
      " [1.00833298]] , b =  [-25.80296732]\n",
      "step =  70000 error value =  0.08296806004018954 W =  [[2.20744027]\n",
      " [1.0105811 ]] , b =  [-25.84510843]\n",
      "step =  70400 error value =  0.08252537779285536 W =  [[2.21061027]\n",
      " [1.01281683]] , b =  [-25.8870255]\n",
      "step =  70800 error value =  0.08208736400272304 W =  [[2.21376377]\n",
      " [1.0150403 ]] , b =  [-25.92872087]\n",
      "step =  71200 error value =  0.08165394555568682 W =  [[2.21690096]\n",
      " [1.01725164]] , b =  [-25.97019688]\n",
      "step =  71600 error value =  0.08122505085095076 W =  [[2.220022  ]\n",
      " [1.01945099]] , b =  [-26.01145579]\n",
      "step =  72000 error value =  0.08080060976218457 W =  [[2.22312705]\n",
      " [1.02163848]] , b =  [-26.05249985]\n",
      "step =  72400 error value =  0.0803805535998661 W =  [[2.22621628]\n",
      " [1.02381422]] , b =  [-26.09333127]\n",
      "step =  72800 error value =  0.07996481507477218 W =  [[2.22928984]\n",
      " [1.02597835]] , b =  [-26.13395223]\n",
      "step =  73200 error value =  0.07955332826259894 W =  [[2.23234789]\n",
      " [1.02813099]] , b =  [-26.17436488]\n",
      "step =  73600 error value =  0.07914602856959277 W =  [[2.23539058]\n",
      " [1.03027225]] , b =  [-26.21457131]\n",
      "step =  74000 error value =  0.07874285269927024 W =  [[2.23841808]\n",
      " [1.03240227]] , b =  [-26.25457362]\n",
      "step =  74400 error value =  0.07834373862009886 W =  [[2.24143051]\n",
      " [1.03452114]] , b =  [-26.29437385]\n",
      "step =  74800 error value =  0.07794862553413381 W =  [[2.24442805]\n",
      " [1.036629  ]] , b =  [-26.33397401]\n",
      "step =  75200 error value =  0.07755745384659682 W =  [[2.24741082]\n",
      " [1.03872594]] , b =  [-26.37337611]\n",
      "step =  75600 error value =  0.07717016513634084 W =  [[2.25037898]\n",
      " [1.04081209]] , b =  [-26.41258208]\n",
      "step =  76000 error value =  0.0767867021271764 W =  [[2.25333267]\n",
      " [1.04288756]] , b =  [-26.45159387]\n",
      "step =  76400 error value =  0.07640700866004449 W =  [[2.25627201]\n",
      " [1.04495244]] , b =  [-26.49041337]\n",
      "step =  76800 error value =  0.0760310296659751 W =  [[2.25919717]\n",
      " [1.04700685]] , b =  [-26.52904247]\n",
      "step =  77200 error value =  0.07565871113984883 W =  [[2.26210826]\n",
      " [1.0490509 ]] , b =  [-26.56748299]\n",
      "step =  77600 error value =  0.07529000011488714 W =  [[2.26500542]\n",
      " [1.05108468]] , b =  [-26.60573677]\n",
      "step =  78000 error value =  0.07492484463789195 W =  [[2.26788878]\n",
      " [1.0531083 ]] , b =  [-26.64380561]\n",
      "step =  78400 error value =  0.07456319374517599 W =  [[2.27075848]\n",
      " [1.05512186]] , b =  [-26.68169125]\n",
      "step =  78800 error value =  0.07420499743918897 W =  [[2.27361464]\n",
      " [1.05712546]] , b =  [-26.71939546]\n",
      "step =  79200 error value =  0.07385020666578446 W =  [[2.27645738]\n",
      " [1.05911919]] , b =  [-26.75691995]\n",
      "step =  79600 error value =  0.07349877329212921 W =  [[2.27928684]\n",
      " [1.06110316]] , b =  [-26.79426641]\n",
      "step =  80000 error value =  0.07315065008523873 W =  [[2.28210313]\n",
      " [1.06307745]] , b =  [-26.83143652]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2  # 1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "for step in  range(80001):  \n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b79d00f-fff6-4a3f-90f9-dce8ced0e375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12866543]), 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예습 3, 복습 17시간\n",
    "test_data = np.array([3,17])\n",
    "predict(test_data)\n",
    "#합격확률 12% fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa49d308-1aa8-4146-ac25-8885fe0e7653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.63501701]), 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([12,0])\n",
    "predict(test_data)\n",
    "#예습이 중요한 영향을 미치는구나!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
